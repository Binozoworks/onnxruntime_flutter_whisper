name: ONNX Models build
run-name: ONNX Models build

on:
  - workflow_dispatch

jobs:
  build-whisper:
    timeout-minutes: 3600
    strategy:
      fail-fast: false
      max-parallel: 2
      matrix:
        whisper-model: [ whisper-tiny, whisper-tiny.en, whisper-base, whisper-base.en, whisper-small, whisper-small.en, whisper-medium, whisper-medium.en, whisper-large, whisper-large-v2, whisper-large-v3, whisper-large-v3-turbo ]
    runs-on: ubuntu-24.04
    name: Building ${{ matrix.whisper-model }} onnx model
    steps:
      - name: Cleanup GitHub bloat
        run: curl -s -L https://raw.githubusercontent.com/apache/flink/02d30ace69dc18555a5085eccf70ee884e73a16e/tools/azure-pipelines/free_disk_space.sh | bash
      - name: Clone Olive
        run: git clone https://github.com/microsoft/Olive.git .

      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip' # cache pip dependencies for faster workflows
      - run: pip install -r requirements.txt
      - run: pip install onnxruntime onnxruntime-extensions
      - run: pip install .

      - name: Building ${{ matrix.whisper-model }}
        working-directory: examples/whisper
        run: |
          python3 prepare_whisper_configs.py --model_name openai/${{ matrix.whisper-model }}
          olive run --config whisper_cpu_int8.json --setup
          olive run --config whisper_cpu_int8.json

      - uses: actions/upload-artifact@v4
        name: Upload generated onnx file
        with:
          name: "${{ matrix.whisper-model }}.onnx"
          path: 'examples/whisper/models/whisper_cpu_int8/model.onnx'
          if-no-files-found: error
          retention-days: 1